"-GLOBAL_DATA:aglobalvariableItisinitializedasadictionaryYoucansavenecessaryinformationbetweendifferentsteps"
"withit"
"##Generalgameinformation"
"-TheversionofMinecraftis111"
"-Commonblocknames:dirt,cobblestone,iron,diamond,wood,coal,water,air,lava,leaves,Collecteditemnamesarethe"
"same"
"-FOVissetto-35to35degreesforyawand-30to30degreesforpitchThemaxvisibledistanceofblocksis64"
"-Lengthofeachblockis1meter"
"-Theycoordinateoftheagentistheagentâ€™sheightThelargerthey,thehighertheagentThegroundlevelisaroundy=63,but"
"isnotfixed"
"-Ateachstep,theagentselectsoneoperationinisactionspaceTheactionspaceincludesdoingnothing(iestayingstill),"
"movingforwardandbackward,jumpingandattackingTheactionspacealsoincludesturningleft,right,upanddown"
"-Theattackrangeis2metersinfrontoftheagentTheagentcanmove02metersineachstepTheagentcanturn15degreesin"
"eachstepTypically,theagentneedstostaystillandattackfor**60successivesteps**tobreakablock"
"-Thehungervalueisalwaysatthemaxlevel"
"##Rewardfunctionrequirements"
"-Youshouldwriteadenserewardfunction`dense`andasparserewardfunction`sparse`Thesparserewardindicatesachieving"
"thegoalorreceivingheavypunishmentThedenserewardprovidesintermediatesignaltoguidetheagentintheprocessof"
"achievingthegoalThemagnitudeofthereturnvaluedoesnotmatter,butthesign(positiveornegative)isimportantThefinal"
"rewardwillbe`npsign(sparse())*1+npsign(dense())*01`"
"##OutputRequirements"
"-TherewardfunctionshouldbewritteninPython39"
"-Outputthecodeblockonly**Donotoutputanythingelseoutsidethecodeblock**"
"-Youshouldinclude**sufficientcomments**inyourrewardfunctiontoexplainyourthoughts,theobjectiveand**implementa-"
"tiondetails**Theimplementationcanbespecifiedtoaspecificlineofcode"
"-Ifyouneedtoimportpackages(egmath,numpy)ordefinehelperfunctions,definethematthebeginningofthefunctionDo"
"notuseunimportedpackagesandundefinedfunctions"
"##Outputformat"
"Strictlyfollowthefollowingformat**Donotoutputanythingelseoutsidethecodeblock**"
"defreward_function(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA):"
"#Thoughts:"
"#"
"#(importpackagesanddefinehelperfunctions)"
"importnumpyasnp"
""
"defdense(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA):"
""
"defsparse(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA):"
""
"dense_reward=dense(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA)"
"sparse_reward=sparse(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA)"
"returnnpsign(sparse_reward)*1+npsign(dense_reward)*01"
""
"NowwritearewardfunctionThenineachiteration,IwillusetherewardfunctiontotrainanRLagent,andtestitinthe"
