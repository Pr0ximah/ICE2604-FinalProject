"-inventory_change:thechangeoftheagent’sinventoryfromtheprevioussteptocurrentstep,intheformofadictionary:"
"{NAME_1:CHANGE_NUM_1,NAME_2:CHANGE_NUM_2}Positivevaluesmeanincreaseandnegativevaluesmeande-"
"creaseForexample,{""wood"":2,""dirt"":3,""stone_pickaxe"":-1}"
"-health:anintegervalueinrange0to10indicatingthehealthleveloftheagent0meansdeathand10meansfullhealth"
"-past_agent_positions:thehistoryoflocationofagent,intheformofalist:[[x1,y1,z1,yaw1,pitch1],[x2,y2,z2,yaw2,pitch2],"
"]Theyawandpitchherearerelativetotheagent’sinitialforwarddirection,ie,pitch=0andyaw=0isthefrontoftheagent"
"whenitwasbornThelengthofthelististhenumberofstepstheagenthastakenThelastelementofthelististhecurrentlocation"
"oftheagent"
"-GLOBAL_DATA:aglobalvariableItisinitializedasadictionaryYoucansavenecessaryinformationbetweendifferentsteps"
"withit"
"##Generalgameinformation"
"-TheversionofMinecraftis111"
"-Commonblocknames:dirt,cobblestone,iron,diamond,wood,coal,water,air,lava,leaves,Collecteditemnamesarethe"
"same"
"-FOVissetto-35to35degreesforyawand-30to30degreesforpitchThemaxvisibledistanceofblocksis64"
"-Lengthofeachblockis1meter"
"-Theycoordinateoftheagentistheagent’sheightThelargerthey,thehighertheagentThegroundlevelisaroundy=63,but"
"isnotfixed"
"-Ateachstep,theagentselectsoneoperationinisactionspaceTheactionspaceincludesdoingnothing(iestayingstill),"
"movingforwardandbackward,jumpingandattackingTheactionspacealsoincludesturningleft,right,upanddown"
"-Theattackrangeis2metersinfrontoftheagentTheagentcanmove02metersineachstepTheagentcanturn15degreesin"
"eachstepTypically,theagentneedstostaystillandattackfor**60successivesteps**tobreakablock"
"-Thehungervalueisalwaysatthemaxlevel"
"##Rewardfunctionrequirements"
"-Youshouldwriteadenserewardfunction`dense`andasparserewardfunction`sparse`Thesparserewardindicatesachieving"
"thegoalorreceivingheavypunishmentThedenserewardprovidesintermediatesignaltoguidetheagentintheprocessof"
"achievingthegoalThemagnitudeofthereturnvaluedoesnotmatter,butthesign(positiveornegative)isimportantThefinal"
"rewardwillbe`npsign(sparse())*1+npsign(dense())*01`"
"##Currentrewardfunction"
"defreward_function(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA):"
""""""""
"Thoughts:"
"Inordertomaketheagentapproachthediamond,weneedtogivepositiverewardsforactionsthat"
"maketheagentgetclosertothediamondandnegativerewardsforactionsthatmaketheagentgetfurtherfromthediamond"
"Wealsoneedtogiveanegativerewardiftheagent’shealthdecreasestoencouragetheagenttoavoiddangeroussituations"
"Thedenserewardfunctionwillbebasedonthedistancetothediamondandhealth"
"Thesparserewardfunctionwillgivealargepositiverewardwhentheagentreachesthediamondandalargenegativereward"
"whentheagentdies"
""""""""
"importnumpyasnp"
"defdense(current_nearest_blocks,previous_nearest_blocks,inventory_change,health,past_agent_positions,"
"GLOBAL_DATA):"
"#Initializereward"
"reward=0"
"#Iftheagentisclosertodiamondthanbefore,giveapositivereward"
"if""diamond""incurrent_nearest_blocksand""diamond""inprevious_nearest_blocks:"
"ifcurrent_nearest_blocks[""diamond""][0]<previous_nearest_blocks[""diamond""][0]:"
"reward+=1"
"elifcurrent_nearest_blocks[""diamond""][0]>previous_nearest_blocks[""diamond""][0]:"
